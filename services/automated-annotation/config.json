{
  "service": {
    "name": "automated-annotation",
    "description": "Automated annotation service using agent architecture for classification tasks. Supports vector-based model classification and LLM-based property classification via orchestration handlers.",
    "version": "2.0.0"
  },
  "deployment": {
    "runtime": "python3.11",
    "timeout": 300,
    "memory": 1024,
    "layers": [
      "arn:aws:lambda:eu-west-2:193757560043:layer:intelligent-functions-python:5"
    ],
    "extra_env": {
      "VERTEXAI_PROJECT": "truss-data-science"
    },
    "_url_config_note": "API URLs are now stage-aware and configured in stage_urls.py. URLs are selected based on STAGE env var (dev/staging/prod)."
  },
  "database": {
    "required": true,
    "connection_type": "dynamodb",
    "permissions": ["read", "write"],
    "tables": [
      "truss-image-processing-${STAGE}",
      "truss-image-processing-dev",
      "truss-image-processing-staging",
      "truss-image-processing-prod",
      "model_visual_classifier_nodes",
      "linesheet-upload-csv-configs-${STAGE}",
      "linesheet-upload-csv-configs-dev",
      "linesheet-upload-csv-configs-staging",
      "linesheet-upload-csv-configs-prod",
      "truss-agent-configs-${STAGE}",
      "truss-agent-configs-dev",
      "truss-agent-configs-staging",
      "truss-agent-configs-prod",
      "truss-agent-schemas-${STAGE}",
      "truss-agent-schemas-dev",
      "truss-agent-schemas-staging",
      "truss-agent-schemas-prod",
      "truss-agent-prompt-templates-${STAGE}",
      "truss-agent-prompt-templates-dev",
      "truss-agent-prompt-templates-staging",
      "truss-agent-prompt-templates-prod"
    ]
  },
  "api": {
    "base_path": "/automations/annotation",
    "cors_enabled": true,
    "_note": "Endpoints with paths starting with '/' are absolute (not relative to base_path). Endpoints without leading '/' are relative to base_path.",
    "endpoints": [
      {
        "path": "/{category}/classify/model",
        "method": "POST",
        "description": "Classify model using vector-based similarity search via model_vector_classifier_api_handler. Uses pre-computed image vectors from image-processing table, queries Pinecone for similar images, and performs majority voting. Returns model, model_id, root_model, root_model_id, and confidence.",
        "parameters": {
          "path": {
            "category": "string (required) - Category (e.g., 'bags')"
          },
          "body": {
            "image": "string (required) - Processing/Image ID (processing_id) stored in the image-processing DynamoDB table. Signed image URL will be looked up automatically.",
            "processing_id": "string (optional) - Alternative to 'image' field",
            "brand": "string (required) - Brand namespace for Pinecone (e.g., 'jacquemus'). Uses 7 nearest neighbors by default",
            "category": "string (optional) - Category for root lookup (default: 'bags')"
          }
        }
      },
      {
        "path": "/{category}/classify/{property}",
        "method": "POST",
        "description": "Classify a property (type, material, colour, etc.) using the new agent architecture system via agent_orchestration_api_handler. Maps category/property to config_id, calls orchestration function, and returns formatted result with IDs and names.",
        "parameters": {
          "path": {
            "category": "string (required) - Category (e.g., 'bags')",
            "property": "string (required) - Property to classify (e.g., 'material', 'colour', 'type', 'condition')"
          },
          "body": {
            "image": "string (optional) - Processing/Image ID. Signed image URL will be looked up automatically from annotation-data-service-layer.",
            "image_url": "string (optional) - Direct image URL (if already signed, takes precedence over image)",
            "text_input": "string (optional) - Pre-formatted text string (takes precedence if provided)",
            "text_metadata": "object (optional) - Text metadata as JSON dict (e.g., {\"brand\": \"...\", \"title\": \"...\", \"description\": \"...\"}). Allows column filtering before passing to agent.",
            "text_dump": "string (optional) - Legacy field - treated as text_input if provided (for backward compatibility)",
            "brand": "string (optional) - Brand name (used to build text_metadata dict if text_metadata not provided)",
            "title": "string (optional) - Title (used to build text_metadata dict if text_metadata not provided)",
            "description": "string (optional) - Description (used to build text_metadata dict if text_metadata not provided)",
            "input_mode": "string (optional) - Input mode: 'auto', 'image-only', 'text-only', 'multimodal' (default: 'auto')"
          }
        }
      },
      {
        "path": "/automations/agents",
        "method": "POST",
        "description": "Direct agent execution endpoint (INTERNAL USE ONLY - called by external orchestration scripts). ARCHITECTURE EXCEPTION: Directly calls agent_architecture (violates normal pattern). DEPRECATED: Will be removed once legacy systems are migrated. New code should use orchestration functions via agent_orchestration_api_handler.",
        "internal": true,
        "_note": "This endpoint is NOT under base_path /automations/annotation - it's a separate root-level endpoint",
        "parameters": {
          "body": {
            "config_id": "string (required) - Agent configuration ID from DynamoDB (e.g., 'material-30', 'classifier-material-bags')",
            "input_data": "object (required) - Task-specific input data: {item_id: string (required), image_url: string (optional), text_input: string (optional), input_mode: string (optional, default: 'auto')}"
          }
        }
      },
      {
        "path": "/health",
        "method": "GET",
        "description": "Health check endpoint for the automated annotation service. Returns service status and stage information.",
        "parameters": {}
      },
      {
        "path": "/csv-config",
        "method": "POST",
        "description": "Generate CSV column mapping configuration using LLM analysis. Analyzes sample rows from a CSV file and produces a mapping that identifies brand, title, description, and image columns. Configs are cached in DynamoDB for reuse.",
        "parameters": {
          "body": {
            "CSV_uuid": "string (required) - Unique identifier for the CSV file",
            "sample_rows": "array (required) - List of 5-10 sample row dicts from the CSV",
            "organisation_uuid": "string (optional) - Organization scope for config lookup/storage",
            "max_chars": "integer (optional) - Maximum characters for sample data (default: 25000)"
          }
        }
      }
    ]
  },
  "aws": {
    "region": "eu-west-2",
    "account_id": "193757560043",
    "vpc_id": "vpc-04e79f1770f4205de"
  },
  "access": {
    "internal": true,
    "external": true,
    "auth_config": {
      "cognito": {
        "user_pool_arn": "arn:aws:cognito-idp:eu-west-2:193757560043:userpool/eu-west-2_JyaPgaRFW",
        "cors_origin": "*"
      },
      "api_key": {
        "cors_origin": "*"
      }
    }
  },
  "llm": {}
}
